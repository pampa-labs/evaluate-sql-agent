{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an evaluation dataset for SQL Agent\n",
    "\n",
    "This notebook is used for building an evaluation dataset containing at least the following:\n",
    "- `question`\n",
    "- `SQL query`\n",
    "- `Natural Language answer parsed from query result`\n",
    "\n",
    "Evaluation dataset is based on databases obtained from **Spider dataset**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelsoria/miniconda3/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.25) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from getpass import getpass\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.utilities import SQLDatabase\n",
    "\n",
    "from utils.evaluation_prompts import TARGET_PROMPT\n",
    "from utils.utils import CustomDatabase\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the whole evaluation dataset\n",
    "\n",
    "You need **Spider dataset** inside `datasets/spider` for this part. You can download it [here](https://drive.google.com/uc?export=download&id=1TqleXec_OykOYFREKKtschzY29dUcVAQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "databases_info = pd.read_json('datasets/spider/tables.json')\n",
    "evaluation_df = pd.read_json('datasets/spider/train_spider.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Filter out databases with percentiles 25, 50, and 75 in terms of number of tables\n",
    "# percentiles = [0.25, 0.5, 0.75]\n",
    "# table_counts = databases_info['table_names'].apply(len)\n",
    "# selected_databases_info = databases_info[table_counts.isin(table_counts.quantile(percentiles))]\n",
    "\n",
    "# Filter only databases containing between 5 and 8 tables\n",
    "filtered_databases_info = databases_info[\n",
    "    (databases_info['table_names'].apply(len) >= 5) &\n",
    "    (databases_info['table_names'].apply(len) <= 8)\n",
    "].copy()\n",
    "\n",
    "len(filtered_databases_info)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these 37 interesting databases (huge filter out of over 150), let's now filter based on criteria on evaluation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insurance_fnol 42\n",
      "store_product 44\n",
      "dog_kennels 0\n",
      "e_learning 82\n",
      "products_for_hire 18\n",
      "dorm_1 100\n",
      "driving_school 93\n",
      "music_2 100\n",
      "sports_competition 52\n",
      "csu_1 70\n",
      "tracking_orders 60\n",
      "insurance_policies 48\n",
      "customers_campaigns_ecommerce 15\n",
      "tracking_share_transactions 41\n",
      "apartment_rentals 80\n",
      "cre_Docs_and_Epenses 84\n",
      "tracking_software_problems 48\n",
      "products_gen_characteristics 86\n",
      "riding_club 17\n",
      "aircraft 46\n",
      "restaurant_1 22\n",
      "insurance_and_eClaims 40\n",
      "college_1 164\n",
      "local_govt_mdm 14\n",
      "hr_1 124\n",
      "soccer_1 14\n",
      "real_estate_properties 0\n",
      "college_3 74\n",
      "yelp 0\n",
      "car_1 0\n",
      "geo 0\n",
      "cre_Doc_Tracking_DB 90\n",
      "activity_1 88\n",
      "customers_and_addresses 88\n",
      "customers_and_products_contacts 15\n",
      "company_1 7\n",
      "product_catalog 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelsoria/miniconda3/lib/python3.10/site-packages/langchain/utilities/sql_database.py:111: SAWarning: Could not instantiate type <class 'sqlalchemy.sql.sqltypes.INTEGER'> with reflected arguments ['11']; using no arguments.\n",
      "  self._metadata.reflect(\n"
     ]
    }
   ],
   "source": [
    "evaluation_databases = []\n",
    "for db_name in list(filtered_databases_info['db_id']):\n",
    "    evaluation_dataset = evaluation_df[evaluation_df['db_id'] == db_name]\n",
    "    database = SQLDatabase.from_uri(f'sqlite:///datasets/spider/database/{db_name}/{db_name}.sqlite')\n",
    "    evaluation_database = CustomDatabase(name=db_name, database=database, evaluation_dataset=evaluation_dataset)\n",
    "    evaluation_databases.append(evaluation_database)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a list of databases between 5 and 8 tables, and evaluation sets for each one of them.\n",
    "\n",
    "Let's pick 3 databases containing ~20 evaluation questions to check how they look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products_for_hire 18\n",
      "riding_club 17\n",
      "restaurant_1 22\n"
     ]
    }
   ],
   "source": [
    "for e in evaluation_databases:\n",
    "    if 15 < len(e.evaluation_dataset) < 25:\n",
    "        print(e.name, len(e.evaluation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_databases_names = ['products_for_hire', 'riding_club', 'restaurant_1']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out only interesting databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_databases = []\n",
    "for db_name in selected_databases_names:\n",
    "    evaluation_dataset = evaluation_df[evaluation_df['db_id'] == db_name]\n",
    "    database = SQLDatabase.from_uri(f'sqlite:///datasets/spider/database/{db_name}/{db_name}.sqlite')\n",
    "    evaluation_database = CustomDatabase(name=db_name, database=database, evaluation_dataset=evaluation_dataset)\n",
    "    selected_databases.append(evaluation_database)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **products_for_hire** database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_databases[0].evaluation_dataset[['question','query']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **riding_club** database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_databases[1].evaluation_dataset[['question','query']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **restaurant_1** database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_databases[2].evaluation_dataset[['question','query']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to query the results of the `queries` inside the `evaluation dataset` for each `evaluation database`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 3644.58it/s]\n",
      "/Users/manuelsoria/Pampa/evaluate-sql-agent/utils/utils.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.evaluation_dataset['query_result'] = results\n",
      "17it [00:00, 4502.03it/s]\n",
      "/Users/manuelsoria/Pampa/evaluate-sql-agent/utils/utils.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.evaluation_dataset['query_result'] = results\n",
      "22it [00:00, 4653.52it/s]\n",
      "/Users/manuelsoria/Pampa/evaluate-sql-agent/utils/utils.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.evaluation_dataset['query_result'] = results\n"
     ]
    }
   ],
   "source": [
    "for db in selected_databases:\n",
    "    db.run_queries()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we parse these query results into a natural language output.\n",
    "\n",
    "**Watch out for token usage in this part as it's using an LLM for parsing the query result into Natural Language**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "target_llm_chain = LLMChain(llm=llm,prompt=TARGET_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing results for products_for_hire...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing results for products_for_hire: 100%|██████████| 18/18 [00:43<00:00,  2.41s/it]\n",
      "/Users/manuelsoria/Pampa/evaluate-sql-agent/utils/utils.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.evaluation_dataset['nl_result'] = results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used 3084 tokens\n",
      "Parsing results for riding_club...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing results for riding_club: 100%|██████████| 17/17 [00:40<00:00,  2.39s/it]\n",
      "/Users/manuelsoria/Pampa/evaluate-sql-agent/utils/utils.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.evaluation_dataset['nl_result'] = results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used 2971 tokens\n",
      "Parsing results for restaurant_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing results for restaurant_1: 100%|██████████| 22/22 [00:28<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used 2543 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/manuelsoria/Pampa/evaluate-sql-agent/utils/utils.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.evaluation_dataset['nl_result'] = results\n"
     ]
    }
   ],
   "source": [
    "for db in selected_databases:\n",
    "    with get_openai_callback() as cb:\n",
    "        print(f\"Parsing results for {db.name}...\")\n",
    "        db.parse_query_results(target_llm_chain)\n",
    "        print(f\"Used {cb.total_tokens} tokens\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving evaluation dataset\n",
    "\n",
    "Now let's keep only relevant columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for db in selected_databases:\n",
    "    db.evaluation_dataset[['db_id', 'question', 'query', 'query_result', 'nl_result']].to_json(f\"datasets/pampa_dataset/{db.name}_eval_dataset.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to manually move the `{db_name}.sqlite` files for these databases into `pampa_dataset` folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
